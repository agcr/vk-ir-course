# ДЗ по теме "Индексация и булев поиск" 

В этом ДЗ вам предстоит:
- Реализовать модель булева поиска с использованием обратного индекса
- Выбить скоры выше бейзлайна в контесте на платформе Kaggle
- Предоставить код, который подтверждает выбитые скоры, причем этот код должен удовлетворять дополнительным требованиям по перформансу и потреблению памяти

Ссылка на контест на Kaggle: https://www.kaggle.com/competitions/boolean-retrieval-homework-vk-ir-spring-2025/

По этой ссылке доступны данные контеста, а также подробно описаны:
- формат датасета
- приемочная метрика
- как засабмитить предсказания модели
и т.п.

В этой же доке мы сфокусируемся на том, как подтвердить выбитые скоры.

Сразу заметим, что главная цель этого ДЗ -- это не обучение какой-то модели, как это обычно бывает в контестах на Kaggle, а написание кода, реализующего вполне конкретный алгоритм (булев поиск), а Kaggle мы тут используем просто как удобную платформу для автоматической проверки вашего решения.
Соответственно, в данном контесте существует единственный идеальный скор (равный 1.0), для выбивания которого надо реализовать булев поиск правильно, а бейзлайн -- это просто некоторое произвольное число ниже чем этот идеальный скор.
Поэтому, в отличие от обычного контеста, вам не нужно стремиться выбить скор как можно выше, а надо сфокусироваться исключительно на побитии бейзлайна.

Мы (организаторы) понимаем, что такой формат контеста не очень хорошо "ложится" на платформу Kaggle, но, тем не менее, решили провести его именно так, потому что:
- хотим познакомить вас как можно раньше с возможностями платформы, т.к. все дальнейшие ДЗ будут проводиться на ней, но в уже более привычном формате, когда вы будете обучать модели
- мы подобрали бейзлайн так, что, если даже в вашем решении будут какие-то минимальные неточности или отличия от нашего "идеального" решения (напр. отличия в токенизации), ваше решение все равно сможет побить бейзлайн

Сдавать код будем на платформе GitHub Classroom: https://classroom.github.com/

Ожидается, что, после того как вы побьете бейзлайн в контесте на Kaggle, вы:
- приджойнитесь к заданию "HW1 Boolean Retrieval" в классруме. Для этого надо будет зайти туда по инвайт-ссылке, которую вам пришлют в чате курса, найти себя в списке студентов и подключить свой аккаунт на гитхабе.
- после этого автоматически создастся ваш личный приватный форк репы курса, в который вы будете коммитить код вашего решения. Этот форк будет "жить" в гитхаб-аккаунте организации https://github.com/vk-ir-course-org/ которую мы создали специально для проведения этого курса. Ваш форк будет доступен только вам и преподавателям/менторам курса.
- создадите в своем форке новую ветку для своего решения, можете назвать ее например _hw1-boolean-retrieval_ (но подойдет и любое другое название на ваш вкус)
- оформите свое решение в виде скрипта _solution.py_ в этой ветке
- запушите ветку на github
- сигнализируете менторам о том, что ваше решение готово к проверке. Это можно сделать через т.н. feedback pull request. Обратите внимание, что при создании вашего форка в нем автоматически создался специальный pull request с названием Feedback (его можно найти на вкладке "Pull requests"). В этот PR автоматически попадают все ваши коммиты, а также через него можно общаться с менторами. Ожидаем, что когда вы все докоммитите и код будет готов к проверке, то вы просто напишите в этот PR что "можно проверять ДЗ", и тэгните менторов. Про все это еще подробно напишем в чате курса.
- обратите внимание, что самостоятельно ставить pull request'ы к официальной репе курса не надо! Вся сдача происходит в вашей приватной репе через автоматически созданный feedback pull request.

После этого мы, т.е. преподаватели, которые будут проверять ваше решение:
- счекаутим вашу ветку
- проверим что ваш _solution.py_ действительно генерит сабмишн, который действительно выбивает те скоры, которые вы выбили на Kaggle

Теперь распишем все это немного детальнее.

## Виртуальное окружение

В своем скрипте вы, возможно, захотите использовать какие-то сторонние библиотеки.
У преподавателя, который будет проверять ваш код, должна быть возможность воспроизвести точно такое же окружение (т.е. тот же набор сторонних библиотек), какое было у вас, когда вы решали этот контест.

Для этого предлагается воспользоваться механизмом виртуальных окружений (т.н. virtualenv).

В "главном" README в корне репы курса подробно расписано, как создать и активировать виртуальное окружение.
Ожидается, что вы:
- Создадите виртуальное окружение, например в папке _.venvs/hw1-boolean-retrieval_ в корне счекаученного на вашу локальную машину вашего форка
- Поставите в него все необходимые библиотеки, напр. `pip install какая-то-библиотека`
- Сохраните итоговое окружение в файлик _requirements.txt_: `pip freeze > requirements.txt`

Сейчас в репе в качестве примера уже лежит файлик _requirements.txt_ с несколькими библиотеками (такими как _nltk_), но вы в своей ветке можете спокойно его перезаписать.

Ожидается, что преподаватель:
- Тоже создаст у себя новое виртуальное окружение
- Поставит в него сохраненные вами библиотеки с помощью команды: `pip install -r requirements.txt`, где _requirements.txt_ будет взят уже из вашей ветки

и дальше будет запускать ваше решение _solution.py_ уже в этом восстановленном виртуальном окружении.

## Скрипт решения solution.py

Ожидается, что в этом скрипте лежит код вашего решения.

Скрипт будет запускаться 3 раза.

Первый раз в режиме построения индекса: `./solution.py --build_index --index_dir=index PATH-TO-CONTEST-DATA`

Подробнее про параметры:
- _PATH-TO-CONTEST-DATA_ -- это путь к папке с данными контеста (т.е. это те самые данные, которые можно скачать с Kaggle командой `kaggle competitions download -c CONTEST-NAME`)
- _--index_dir_ -- путь к директории в которой ваш скрипт должен сохранить построенный обратный индекс (т.е. в данном примере папка называется _index_)
- _--build_index_ -- флаг, включающий режим построения индекса

Ожидаем, что в этом режиме ваш скрипт проиндексирует все документы из датасета, и сохранит получившийся обратный индекс на диск в папку index.

После этого скрипт будет запущен еще раз, на этот раз в режиме генерации сабмишна, вот так: `./solution.py --submission_file=submission.csv --index_dir=index CONTEST-DATA`

Тут:
- _--submission_file_ - это как раз путь до сабмишна, который и должен сгенерить ваш скрипт

Ожидаем, что ваш скрипт:
- загрузит сохраненный ранее обратный индекс из папки index
- прогонит через него поисковые запросы, и найдет все документы, в которых встречаются все слова запроса (т.е. рассматриваем многословные запросы как И-запросы)
- сгенерит точно такой же _submission.csv_, как тот, который вы залили на Kaggle в качестве решения.

И, наконец, ваш скрипт будет запущен в 3й раз, в режиме ограничения потребляемой памяти: `systemd-run --quiet --user --scope -p MemoryMax=100M -p MemorySwapMax=0 ./solution.py --submission_file=submission.csv --index_dir=index CONTEST-DATA`

Ожидаем, что в этом режиме ваше решение уложится в 100 MB потребляемой памяти!
Этот лимит подобран так, чтобы для успешной сдачи задания вам пришлось реализовать какой-то из эффективных способов хранения индекса.

Еще несколько важных для воспроизводимости моментов:
- ожидаем, что для токенизации и нормализации текста вы будете использовать функцию preprocess() которая уже реализована в _solution.py_
- проверять решение будем на Linux-машинах, поэтому избегайте в своем решении каких-то конструкций, которые могут не заработать под Linux
- будьте готовы что проверяющий придет к вам с уточняющими вопросами если у него что-то не будет запускаться, или воспроизводиться и т.п. Ожидается, что все общение с проверяющим будет происходить в комментариях к feedback pull request.
- надо понимать, что потребление скриптом памяти зависит от многих факторов, в т.ч. от набора используемых библиотек, поэтому, даже если ваш скрипт превысит лимиты, но мы увидим, что вы реализовали обратный индекс эффективно, то мы все равно зачтем ваше решение

На этом все, надеемся что вам понравится решать этот контест!
