# ДЗ по теме "Машинное обучение ранжированию" 

В этом ДЗ вам предстоит:
- Обучить модель, которая побьет бейзлайн в контесте на платформе Kaggle
- Предоставить код, который подтверждает выбитые скоры

Ссылка на контест на Kaggle: https://www.kaggle.com/competitions/learning-to-rank-homework-vk-ir-spring-2025/

По этой ссылке доступны данные контеста, а также подробно описаны:
- формат датасета
- что и как учить
- приемочная метрика
- как засабмитить предсказания модели
и т.п.

В этой же доке мы сфокусируемся на том, как подтвердить выбитые скоры.

Ожидается, что, после того как завершится контест, вы:
- приджойнитесь к заданию "HW3 Learning to Rank" в классруме. Для этого надо будет зайти туда по инвайт-ссылке, которую вам пришлют в чате курса, найти себя в списке студентов и подключить свой аккаунт на гитхабе.
- после этого автоматически создастся ваш личный приватный форк репы курса, в который вы будете коммитить код вашего решения. Этот форк будет "жить" в гитхаб-аккаунте организации https://github.com/vk-ir-course-org/ которую мы создали специально для проведения этого курса. Ваш форк будет доступен только вам и преподавателям/менторам курса.
- создадите в своем форке новую ветку для своего решения, можете назвать ее например _hw3-learning-to-rank_ (но подойдет и любое другое название на ваш вкус)
- оформите свое решение в виде скрипта _solution.py_ в этой ветке
- запушите ветку на github
- сигнализируете менторам о том, что ваше решение готово к проверке. Это можно сделать через т.н. feedback pull request. Обратите внимание, что при создании вашего форка в нем автоматически создался специальный pull request с названием Feedback (его можно найти на вкладке "Pull requests"). В этот PR автоматически попадают все ваши коммиты, а также через него можно общаться с менторами. Ожидаем, что когда вы все докоммитите и код будет готов к проверке, то вы просто напишите в этот PR что "можно проверять ДЗ", и тэгните менторов. Про все это еще подробно напишем в чате курса.
- обратите внимание, что самостоятельно ставить pull request'ы к официальной репе курса не надо! Вся сдача происходит в вашей приватной репе через автоматически созданный feedback pull request.

После этого мы, т.е. преподаватели, которые будут проверять ваше решение:
- счекаутим вашу ветку
- проверим что ваш _solution.py_ действительно генерит сабмишн, который действительно выбивает те скоры, которые вы выбили на Kaggle

Теперь распишем все это немного детальнее.

## Виртуальное окружение

В своем скрипте вы скорее всего будете использовать какие-то фреймворки или библиотеки для обучения моделей, такие как, например, _catboost_.
У преподавателя, который будет проверять ваш код, должна быть возможность воспроизвести точно такое же окружение (т.е. тот же набор сторонних библиотек), какое было у вас, когда вы обучали модель.

Для этого предлагается воспользоваться механизмом виртуальных окружений (т.н. virtualenv).

В "главном" README в корне репы курса подробно расписано, как создать и активировать виртуальное окружение.
Ожидается, что вы:
- Создадите виртуальное окружение, например в папке _.venvs/hw3-learning-to-rank_ в корне счекаученного на вашу локальную машину вашего форка
- Поставите в него все необходимые библиотеки, напр. `pip install catboost`
- Сохраните итоговое окружение в файлик _requirements.txt_: `pip freeze > requirements.txt`

Сейчас в репе в качестве примера уже лежит файлик _requirements.txt_ с несколькими библиотеками (такими как _pandas_), но вы в своей ветке можете спокойно его перезаписать.

Ожидается, что преподаватель:
- Тоже создаст у себя новое виртуальное окружение
- Поставит в него сохраненные вами библиотеки с помощью команды: `pip install -r requirements.txt`, где _requirements.txt_ будет взят уже из вашей ветки

и дальше будет запускать ваше решение _solution.py_ уже в этом восстановленном виртуальном окружении.

## Скрипт решения solution.py

Ожидается, что в этом скрипте лежит код, воспроизводящий ваши модель и сабмишн, который вы засабмитили на Kaggle.

Скрипт будет запускаться 2 раза.

Первый раз в режиме обучения модели: `./solution.py --train --model_file=output.model PATH-TO-CONTEST-DATA`

Подробнее про параметры:
- _PATH-TO-CONTEST-DATA_ -- это путь к папке с данными контеста (т.е. это те самые данные, которые можно скачать с Kaggle командой `kaggle competitions download -c CONTEST-NAME`)
- _--model_file_ -- файл, в котором ваш скрипт должен сохранить обученную модель (т.е. в данном примере она сохраняется как output.model)
- _--train_ -- флаг, включающий режим обучения модели

Ожидаем, что в этом режиме ваш скрипт обучит модель ранжирования и сохранит ее в файлике output.model.

После этого скрипт будет запущен еще раз, на этот раз в режиме генерации сабмишна, вот так: `./solution.py --submission_file=submission.csv --model_file=output.model PATH-TO-CONTEST-DATA`

Тут:
- _--submission_file_ - это как раз путь до сабмишна, который и должен сгенерить ваш скрипт

Ожидаем, что ваш скрипт:
- загрузит сохраненную ранее модель из файла output.model
- применит эту модель к тестовому множеству
- сгенерит точно такой же submission.csv, как тот, который вы залили на Kaggle в качестве решения.

Если, по каким-то причинам (напр. если не получилось зафиксировать генератор случайных чисел), этот сабмишн будет отличаться от залитого, то ожидаем что он выбьет плюс-минус точно такие же скоры, которые вы выбили на Kaggle.

Тем не менее, постарайтесь, пожалуйста, зафиксировать в своем скрипте генераторы случайных чисел.

Еще несколько важных для воспроизводимости моментов:
- проверять решение будем на Linux-машинах, поэтому избегайте в своем решении каких-то конструкций, которые могут не заработать под Linux
- проверять будем на машине с GPU, т.е. в своем решении можете смело использовать GPU
- будет полезно если вы закоммитите в свою ветку рядом с файлом _solution,py_ еще и модель, которая получилась у вас
- если на этапе обучения модели вы подбирали гиперпараметры, то будет полезно если в коде (или в комментарии к PR) вы укажете еще и лучший набор гиперпараметров который у вас получился т.к. проверяющим обычно очень сложно воспрозводить подбор гиперпараметров
- будьте готовы что проверяющий придет к вам с уточняющими вопросами если у него что-то не будет запускаться, или воспроизводиться и т.п. Ожидается, что все общение с проверяющим будет происходить в комментариях к feedback pull request'у.

На этом все, надеемся что вам понравится решать этот контест!
